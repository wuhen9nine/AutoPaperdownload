import pyautogui
import time
import random
import os
import math

# === âš™ï¸ é…ç½®åŒºåŸŸ ===

# å›¾ç‰‡æ–‡ä»¶å
IMAGE_NAME = 'target.jpeg'

# åŒ¹é…ç›¸ä¼¼åº¦
CONFIDENCE = 0.8           

# æ£€æµ‹é¢‘ç‡ (ç§’)
CHECK_INTERVAL = 0.5       

# âš ï¸ã€å…³é”®ä¿®æ”¹ã€‘æœç´¢åŒºåŸŸè®¾ç½®
# å¦‚æœä½ çš„å±å¹•å¾ˆå¤§ï¼ˆ4Kï¼‰æˆ–é‡åˆ°å†…å­˜æŠ¥é”™ï¼Œè¯·å–æ¶ˆä¸‹é¢å…ƒç»„çš„æ³¨é‡Šï¼Œå¡«å…¥å¤§æ¦‚çš„åæ ‡èŒƒå›´
# æ ¼å¼ï¼š(å·¦è¾¹è·, ä¸Šè¾¹è·, å®½åº¦, é«˜åº¦)
# ä¾‹å¦‚ï¼šSEARCH_REGION = (0, 0, 1920, 1080)  # åªåœ¨å·¦ä¸Šè§’çš„ 1920x1080 åŒºåŸŸæ‰¾
SEARCH_REGION = None 

# ====================

# å…³é—­ PyAutoGUI çš„è§’è½è‡ªåŠ¨æŠ¥é”™æœºåˆ¶ï¼ˆé˜²æ­¢é¼ æ ‡éšæœºç§»åŠ¨åˆ°è¾¹ç¼˜æ—¶ç¨‹åºå´©æºƒï¼‰
pyautogui.FAILSAFE = False

def get_image_path():
    """è·å–å›¾ç‰‡ç»å¯¹è·¯å¾„"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(current_dir, IMAGE_NAME)

def get_bezier_point(t, p0, p1, p2, p3):
    """è®¡ç®—ä¸‰é˜¶è´å¡å°”æ›²çº¿ä¸Šçš„ç‚¹"""
    u = 1 - t
    tt = t * t
    uu = u * u
    uuu = u * u * u
    ttt = tt * t
    
    x = uuu * p0[0] + 3 * uu * t * p1[0] + 3 * u * tt * p2[0] + ttt * p3[0]
    y = uuu * p0[1] + 3 * uu * t * p1[1] + 3 * u * tt * p2[1] + ttt * p3[1]
    return (x, y)

def human_move(target_x, target_y, duration):
    """
    æ‹ŸäººåŒ–ç§»åŠ¨æ ¸å¿ƒé€»è¾‘ï¼š
    ç”Ÿæˆéšæœºè´å¡å°”æ›²çº¿ï¼Œå¹¶é…åˆç¼“åŠ¨ç®—æ³•ï¼ˆèµ·æ­¥å¿«ï¼Œç»ˆç‚¹æ…¢ï¼‰
    """
    start_x, start_y = pyautogui.position()
    dist = math.hypot(target_x - start_x, target_y - start_y)
    
    # è·ç¦»å¤ªè¿‘ç›´æ¥ç§»åŠ¨ï¼Œä¸ç”»æ›²çº¿
    if dist < 50:
        pyautogui.moveTo(target_x, target_y, duration=duration, tween=pyautogui.easeOutQuad)
        return

    # 1. è®¾ç½®éšæœºæ§åˆ¶ç‚¹ï¼ˆäº§ç”Ÿå¼§åº¦ï¼‰
    offset = dist * random.uniform(0.2, 0.5)
    cp1_x = start_x + (target_x - start_x) * 0.3 + random.uniform(-offset, offset)
    cp1_y = start_y + (target_y - start_y) * 0.3 + random.uniform(-offset, offset)
    cp2_x = start_x + (target_x - start_x) * 0.7 + random.uniform(-offset, offset)
    cp2_y = start_y + (target_y - start_y) * 0.7 + random.uniform(-offset, offset)

    # 2. æ²¿æ›²çº¿ç§»åŠ¨
    steps = int(duration * 60)
    if steps < 10: steps = 10
    
    old_pause = pyautogui.PAUSE
    pyautogui.PAUSE = 0  # ä¸´æ—¶å–æ¶ˆå†…éƒ¨æš‚åœï¼Œä¿è¯ä¸æ»‘
    
    start_time = time.time()
    
    for i in range(steps + 1):
        progress = i / steps
        # äºŒæ¬¡ç¼“å‡ºç®—æ³• (Ease Out): æ¥è¿‘ç»ˆç‚¹æ—¶å‡é€Ÿ
        eased_progress = 1 - (1 - progress) * (1 - progress)
        
        x, y = get_bezier_point(
            eased_progress, 
            (start_x, start_y), 
            (cp1_x, cp1_y), 
            (cp2_x, cp2_y), 
            (target_x, target_y)
        )
        
        pyautogui.moveTo(x, y)
        
        # ç®€å•çš„å¸§ç‡æ§åˆ¶
        elapsed = time.time() - start_time
        expected = duration * progress
        if expected > elapsed:
            time.sleep(expected - elapsed)

    # 3. æœ€ç»ˆä¿®æ­£
    pyautogui.moveTo(target_x, target_y)
    pyautogui.PAUSE = old_pause

def simulate_human_click(location):
    """æ¨¡æ‹Ÿäººç±»ç‚¹å‡»æµç¨‹"""
    if location:
        x, y = pyautogui.center(location)
        
        # ç›®æ ‡ç‚¹éšæœºåç§» (é˜²æ­¢æ€»æ˜¯ç‚¹å‡»åŒä¸€ä¸ªåƒç´ )
        final_x = x + random.randint(-5, 5)
        final_y = y + random.randint(-5, 5)
        
        print(f"âœ… å‘ç°ç›®æ ‡ï¼åæ ‡: ({final_x}, {final_y})ï¼Œæ­£åœ¨ç§»åŠ¨...")
        
        # éšæœºè€—æ—¶ (0.5 - 1.2ç§’)
        move_time = random.uniform(0.5, 1.2)
        
        # æ‰§è¡Œæ‹Ÿäººç§»åŠ¨
        human_move(final_x, final_y, duration=move_time)
        
        # æ¨¡æ‹Ÿäººç±»ç¡®è®¤æ—¶çš„å¾®å°åœé¡¿
        time.sleep(random.uniform(0.1, 0.2))
        pyautogui.click()
        return True
    return False

def main():
    target_path = get_image_path()
    
    print("=" * 40)
    print(f"ğŸ¤– è¶…çº§è‡ªåŠ¨ç‚¹å‡»å™¨ (æ‹Ÿäºº+é˜²å´©ç‰ˆ)")
    print(f"ğŸ“‚ æ­£åœ¨ç›‘å¬å›¾ç‰‡: {IMAGE_NAME}")
    print(f"ğŸ›‘ åœæ­¢è¿è¡Œè¯·æŒ‰ Ctrl+C")
    if SEARCH_REGION:
        print(f"ğŸ” å·²å¯ç”¨åŒºåŸŸæœç´¢ä¼˜åŒ–: {SEARCH_REGION}")
    print("=" * 40)
    
    if not os.path.exists(target_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ–‡ä»¶ {target_path}")
        print("è¯·ç¡®ä¿å›¾ç‰‡å’Œè„šæœ¬åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")
        return

    # --- ä¸»å¾ªç¯ç»“æ„ä¼˜åŒ– ---
    while True:
        try:
            # 1. å¯»æ‰¾å›¾ç‰‡
            # region å‚æ•°èƒ½æå¤§é™ä½å†…å­˜å ç”¨ï¼Œæå‡é€Ÿåº¦
            location = pyautogui.locateOnScreen(
                target_path, 
                confidence=CONFIDENCE, 
                grayscale=True,
                region=SEARCH_REGION
            )
            
            # 2. å¦‚æœæ‰¾åˆ°ï¼ˆæ²¡æŠ¥é”™ä¸”ä¸ä¸ºNoneï¼‰ï¼Œæ‰§è¡Œç‚¹å‡»
            if location:
                simulate_human_click(location)
                print("â³ ç‚¹å‡»å®Œæˆï¼Œå†·å´ 3 ç§’...")
                time.sleep(random.uniform(2.5, 4.0))
            
        except pyautogui.ImageNotFoundException:
            # æ‰¾ä¸åˆ°å›¾ç‰‡æ˜¯å¸¸æ€ï¼Œç›´æ¥è·³è¿‡è¿›å…¥ä¸‹ä¸€æ¬¡å¾ªç¯
            pass
            
        except Exception as e:
            # âš ï¸ æ•è·æ‰€æœ‰å…¶ä»–ä¸¥é‡é”™è¯¯ï¼ˆå¦‚å†…å­˜æº¢å‡ºã€æ–‡ä»¶è¢«å ç­‰ï¼‰
            # è¿™é‡Œä¸ä¼šé€€å‡ºç¨‹åºï¼Œè€Œæ˜¯æ‰“å°é”™è¯¯å¹¶é‡è¯•
            print(f"\nâš ï¸ å‘ç”Ÿé”™è¯¯: {e}")
            print("ğŸ”„ ç¨‹åºæœªå´©æºƒï¼Œå°†åœ¨ 3 ç§’åå°è¯•æ¢å¤...")
            time.sleep(3)
        
        # æ¯æ¬¡æ‰«æåçš„é—´éš”
        time.sleep(CHECK_INTERVAL)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·æ‰‹åŠ¨åœæ­¢äº†ç¨‹åºã€‚")